{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45539c7-1187-457e-a8e5-5488437843dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e8380-c30a-41d7-93b6-f9d946d302c6",
   "metadata": {},
   "source": [
    "## API Key Setup and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04b8884-9ea7-4965-8085-c83a6b3445f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa4ff9d-9306-4b4f-8147-c408b9e0ef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run--c8c61a39-ceb0-4885-8ef7-b67a22243314-0' usage_metadata={'input_tokens': 4, 'output_tokens': 17, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_response = llm.invoke(\"Tell me a joke\")\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ac52e-a12c-430e-a77a-d77ee7cdfbd6",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d694a1-99b1-42f5-83da-a1b7c48a258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac93b974-2133-4b84-8583-527c8a81d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed120e2a-4fcf-4c90-a6da-91a44054a5b4",
   "metadata": {},
   "source": [
    "## Simple Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f61f28-b7b8-477b-b369-3a2784e6a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26fa76b-6a74-4b92-9025-ffcee33ca957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Sun is a nearly perfect sphere of hot plasma, held together by its own gravity.  It's a main-sequence star, meaning it generates energy through nuclear fusion in its core, converting hydrogen into helium. This process releases enormous amounts of energy in the form of light, heat, and other forms of radiation, which are essential for life on Earth.  The Sun accounts for about 99.86% of the total mass of the Solar System.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Tell me something about sun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce49d4f-6706-434f-a736-45f9c3836a29",
   "metadata": {},
   "source": [
    "## Structured Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9f70d5-84a9-4984-92b1-9c058eacd54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileReview(phone_model='Galaxy S21', rating=4.0, pros=['Gorgeous screen', 'Amazing camera, especially at night', 'Solid battery life'], cons=['Pricey', 'No charger included', 'New button layout takes some getting used to'], summary=\"Great phone, but a few annoying quirks keep it from being perfect. If you're due for an upgrade, definitely worth checking out!\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MobileReview(BaseModel):\n",
    "    phone_model: str = Field(description=\"Name and model of the phone  '\\n'\")\n",
    "    rating: float = Field(description=\"Overall rating out of 5\")\n",
    "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
    "    cons: List[str] = Field(description=\"List of negative aspects\")\n",
    "    summary: str = Field(description=\"Brief summary of the review\")\n",
    "\n",
    "review_text = \"\"\"\n",
    "Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous,\n",
    "colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
    "stronger. Battery life's solid, lasts me all day no problem.\n",
    "Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
    "Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
    "Overall, I'd say it's a solid 4 out of 5. Great phone, but a few annoying quirks keep it from\n",
    "being perfect. If you're due for an upgrade, definitely worth checking out!\n",
    "\"\"\"\n",
    "\n",
    "structured_llm = llm.with_structured_output(MobileReview)\n",
    "output = structured_llm.invoke(review_text)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba93a15-ade1-49bf-bdce-2d7b24151bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gorgeous screen',\n",
       " 'Amazing camera, especially at night',\n",
       " 'Solid battery life']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42134a39-83ad-4936-ae47-445afac5d2a7",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c93412-b0be-444c-9669-79c43394bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?  Because light attracts bugs!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke({\"topic\": \"programming\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d8cb6-30c2-4c4b-b37f-0d76a3945729",
   "metadata": {},
   "source": [
    "## LLM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de1c8c5-48cb-498c-a4f6-7a475730de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that tells jokes.\"),\n",
    "    HumanMessage(content=\"Tell me about programming\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "479bc6a3-3e99-4e04-960a-e684cb26f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the car get a flat tire?  Because it ran over a nail!\n",
      "\n",
      "\n",
      "What do you call a car that can't stop?  A runaway!\n",
      "\n",
      "\n",
      "Why did the bicycle fall over? Because it was two tired! (This one's a bit of a cheat, but it's related to vehicles!)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that tells jokes.\"),\n",
    "    (\"human\", \"Tell me about {topic}\")\n",
    "])\n",
    "chain = template | llm\n",
    "response = chain.invoke({\"topic\": \"cars\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7c285-aac3-4060-8eb1-36372bb7056a",
   "metadata": {},
   "source": [
    "## Document Processing for RAG Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88918845-7f3e-4462-9ad3-fc41a9d19afa",
   "metadata": {},
   "source": [
    "### 1. Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ac7dde-978f-439e-8435-f091346034b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents from the folder.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "def load_documents(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\")\n",
    "            continue\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "folder_path = \"contents/docs/\"\n",
    "documents = load_documents(folder_path)\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da5129-ec3f-4227-9feb-e645614d5eed",
   "metadata": {},
   "source": [
    "### 2. Splitting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b819342-a692-4380-b229-f0accd983963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents into 6 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split the documents into {len(splits)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7ebd7-f259-4418-8d53-ea41c0950c40",
   "metadata": {},
   "source": [
    "### 3. Creating google genAi Embeddings for RAG Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4c027b2-1eb5-446c-b376-4de7df13643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 6 document chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "document_embeddings = embeddings.embed_documents([split.page_content for split in splits])\n",
    "print(f\"Created embeddings for {len(document_embeddings)} document chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79aa60c-7303-4ba2-9131-6e0350a65486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5f844-e7a6-483e-b567-b9eca64ad378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73b682-e1f8-48c6-b2ed-e91b73ebe9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4a048-afd7-40ea-b91e-87e4c4047148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf47bf3-55f3-43d5-801d-faaedc27d19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c11b6-f79f-4171-9e00-ab2342798fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
